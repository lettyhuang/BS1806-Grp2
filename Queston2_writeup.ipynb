{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anna Kurek - 01444623  \n",
    "Linyun Huang - 01379982  \n",
    "Mark O'Shea - 01384962  \n",
    "Mingyang Tham - 01428168  \n",
    "Rejpal Matharu - 01367169  \n",
    "Yiting Wang - 01423116"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data into a Python data frame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('SMSSpamCollection', 'r')\n",
    "file = file.readlines()\n",
    "data=pd.DataFrame(file)\n",
    "data.columns=['x']\n",
    "data=data['x'].str.split('\\t',expand=True)\n",
    "data.columns=['Label','Message']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "### 2. Pre-process the SMS messages: Remove all punctuation and numbers from the SMS messages, and change all messages to lower case. (Please provide the Python code that achieves this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Message']=data['Message'].str.lower()\n",
    "data['Message'] = data['Message'].str.replace('[^\\w\\s]','')\n",
    "data['Message'] = data['Message'].str.replace('\\d+', '')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Shuffle the messages and split them into a training set (2,500 messages), a validation set (1,000 messages) and a test set (all remaining messages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test,train, = train_test_split(data, test_size=2500,random_state=12)\n",
    "test, valid = train_test_split(test, test_size=1000,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. While Python’s SciKit-Learn library has a Naive Bayes classifier, it works with continuous probability distributions and assumes numerical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayesForSpam:\n",
    "    def train (self, hamMessages, spamMessages):\n",
    "        self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (hamMessages)) / (len (hamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in hamMessages if w in m])) / len (hamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "        \n",
    "    def train2 (self, hamMessages, spamMessages):\n",
    "        self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (hamMessages)) / (len (hamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        spamkeywords = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in hamMessages if w in m])) / len (hamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            if prob1 * 20 < prob2:\n",
    "                self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "                spamkeywords.append (w)\n",
    "        self.words = spamkeywords\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "\n",
    "    def predict (self, message):\n",
    "        posteriors = np.copy (self.priors)\n",
    "        for i, w in enumerate (self.words):\n",
    "            if w in message.lower():  # convert to lower-case\n",
    "                posteriors *= self.likelihoods[:,i]\n",
    "            else:                                   \n",
    "                posteriors *= np.ones (2) - self.likelihoods[:,i]\n",
    "            posteriors = posteriors / np.linalg.norm (posteriors)  # normalise\n",
    "        if posteriors[0] > 0.5:\n",
    "            return ['ham', posteriors[0]]\n",
    "        return ['spam', posteriors[1]]    \n",
    "\n",
    "    def score (self, messages, labels):\n",
    "        confusion = np.zeros(4).reshape (2,2)\n",
    "        for m, l in zip (messages, labels):\n",
    "            if self.predict(m)[0] == 'ham' and l == 'ham':\n",
    "                confusion[0,0] += 1\n",
    "            elif self.predict(m)[0] == 'ham' and l == 'spam':\n",
    "                confusion[0,1] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'ham':\n",
    "                confusion[1,0] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'spam':\n",
    "                confusion[1,1] += 1\n",
    "        return (confusion[0,0] + confusion[1,1]) / float (confusion.sum()), confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Explain the code: What is the purpose of each function? What do ’train’ and ‘train2’ do, and what is the difference between them? Where in the code is Bayes’ Theorem being applied?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the above \"train\" function is to first calculate the prior probability, and then create a likelihood table for each word (P(word|Spam) & P(word|Ham) in order to further be used to calculate the posterior probability and determine whether they are more likely to be spam or ham using Naive Bayes Algorithm. Notice that each likehood will not exceed 0.95 since the function restricts the highest likelihood to 0.95.\n",
    "\n",
    "The purpose of the above \"train2\" function is to first calculate the prior probability of ham and spam message given the number of messages in each category. Next, the function will return a likelihood table just as what \"train\" function does. However, \"train2\" function will compare each word's likelihood in spam/ham message and if the Spam prob is 20 times higher the Ham prob, it means that the word has a very high appreance in Spam and thus the function will create a list of these words and classified as Spam key word.\n",
    "\n",
    "The purpose of the above \"predict\" function is predict whether a new input message is ham or spam. This function first identify whether each word within the input message is in the spam key word list or not, then further calculate the posterior probability using Naive Bayes Algorithm. This is whether Bayes' Theorem is applied.\n",
    "\n",
    "The purpose of the above \"score\" function is to return a confusion matrix specifying the overall predict result from the \"predict\" function. We can see from the matrix whether the Naive Bayes Classification return the correct classifier of the input message.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Use your training set to train the classifiers ‘train’ and ‘train2’. Note that the interfaces of our classifiers require you to pass the ham and spam messages separately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = train['Label']=='ham'\n",
    "ham = list(train[mask]['Message'])\n",
    "spam = list(train[~mask]['Message'])\n",
    "\n",
    "m1=NaiveBayesForSpam()\n",
    "\n",
    "m1.train(ham,spam)\n",
    "\n",
    "m2=NaiveBayesForSpam()\n",
    "m2.train2(ham,spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Using the validation set, explore how each of the two classifiers performs out of sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96499999999999997, array([[ 860.,   31.],\n",
       "        [   4.,  105.]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_messages=list(valid['Message'])\n",
    "valid_labels=list(valid['Label'])\n",
    "\n",
    "m1.score(valid_messages, valid_labels)\n",
    "m2.score(valid_messages, valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy rate of train model is 0.9600.\n",
    "\n",
    "The accuracy rate of train2 model is 0.9680\n",
    "\n",
    "Both classifiers have very high accuracy rate, however in this case train classifier performs \n",
    "slightly better than train2 classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Why is the ‘train2’ classifier faster? Why does it yield a better accuracy both on the training and the validation set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the \"train2\" classifier first filters out the most popular spam word and then conduct the prediction. This makes the algorithm much faster since it does not need to examine each word in spam category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. How many false positives (ham messages classied as spam messages) did you get in your validation set? How would you change the code to reduce false positives at the expense of possibly having more false negatives (spam messages classified as ham messages)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Run the ‘train2’ classifier on the test set and report its performance using a confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96769527483124396, array([[ 1794.,    56.],\n",
       "        [   11.,   213.]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tmessages=list(test[\"Message\"])\n",
    "Tlabels=list(test[\"Label\"])\n",
    "\n",
    "m2.score(Tmessages,Tlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
